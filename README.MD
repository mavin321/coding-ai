# ğŸš€ AI Coding Assistant

A full-stack AI-powered coding assistant built with:

- **Python (FastAPI)** for the backend
- **React** for the frontend
- **PyTorch + HuggingFace Transformers** for the AI model
- **LoRA fine-tuning** support for custom training

This tool can:

- âœ¨ Explain code
- âœ¨ Generate code
- âœ¨ Refactor code
- âœ¨ Create unit tests
- âœ¨ Fine-tune itself on your own dataset to improve performance

---

# ğŸ“¦ Features

### ğŸ§  AI-Powered Code Assistant

Your model can perform:

| Feature              | Description                                     |
| -------------------- | ----------------------------------------------- |
| **Explain code**     | Breaks down code into human explanations        |
| **Generate code**    | Creates code from natural-language instructions |
| **Refactor code**    | Produces cleaner, more Pythonic versions        |
| **Write unit tests** | Generates test suites for any function          |

The AI backend uses your own model defined in `backend/model_client.py`
and can be swapped for a fine-tuned LoRA model.

---

### ğŸŒ Full Web Application (React + FastAPI)

- Beautiful browser interface
- Interactive forms
- Text areas for input/output
- API calls to backend via Axios
- Real-time responses

---

### ğŸ‹ï¸â€â™‚ Fine-tuning Support (Level 2)

Train the AI on your own dataset using:

- HuggingFace Transformers
- LoRA adapters (PEFT)
- Custom instruction-based datasets

Training code lives inside:

```
backend/finetune/
```

---

# ğŸ“‚ Project Structure

```
coding-ai/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ model_client.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ ai.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.js
â”‚       â”œâ”€â”€ api.js
â”‚       â””â”€â”€ index.js
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.jsonl
â”‚   â””â”€â”€ val.jsonl
â”‚
â””â”€â”€ README.md
```

---

# ğŸ› ï¸ Installation Instructions

This project has **two parts**:

- Backend (FastAPI + Model)
- Frontend (React App)

Follow the steps below.

---

# âš™ï¸ Backend Setup (FastAPI + Model)

### 1. Create virtual environment

```bash
cd coding-ai
python -m venv venv
```

Activate it:

**Windows**

```bash
venv\Scripts\activate
```

**Mac/Linux**

```bash
source venv/bin/activate
```

---

### 2. Install backend dependencies

Inside `venv`, run:

```bash
pip install -r backend/requirements.txt
```

If you don't have a requirements file, install manually:

```bash
pip install fastapi uvicorn transformers torch peft datasets accelerate
```

---

### 3. Start the backend server

Make sure you are inside the **project root** (`coding-ai`), then run:

```bash
uvicorn backend.main:app --reload --port 8000
```

Your API will run at:

```
http://localhost:8000
```

API docs:

```
http://localhost:8000/docs
```

---

# ğŸŒ Frontend Setup (React)

### 1. Install dependencies

```bash
cd frontend
npm install
```

### 2. Run frontend

```bash
npm start
```

Frontend will open at:

```
http://localhost:3000
```

---

# ğŸ”Œ How Backend & Frontend Communicate

The frontend sends JSON requests to FastAPI:

```
POST /api/ai/explain
POST /api/ai/generate
POST /api/ai/refactor
POST /api/ai/tests
```

Each returns:

```json
{
  "response": "...AI output..."
}
```

---

# ğŸ§  AI Model Configuration

Your model is defined in:

```
backend/config.py
```

Change:

```python
MODEL_NAME = "Salesforce/codegen-350M-multi"
```

to your preferred model.

---

# ğŸ§© Prompts

The prompts that control model behavior are stored in:

```
backend/prompts.py
```

You can edit:

- Explanation style
- Refactor style
- Test structure
- Code generation quality

---

# ğŸ‹ï¸ Fine-Tuning (Level 2)

Fine-tuning uses:

- HuggingFace Datasets
- LoRA (PEFT)
- Training scripts in:

```
backend/finetune/
```

### 1. Add training data

Format (JSONL):

```json
{
  "instruction": "Explain this code",
  "input": "def x(a): return a+1",
  "output": "Adds 1 to a"
}
```

Place files in:

```
data/train.jsonl
data/val.jsonl
```

---

### 2. Run fine-tuning

```bash
cd backend/finetune
python train_lora.py
```

Your LoRA weights will be saved in:

```
lora-output/
```

---

### 3. Use fine-tuned model

Edit `backend/model_client.py`:

```python
LORA_PATH = "lora-output"
```

Now your backend will load the trained model.

---

# ğŸ§ª Example API Calls

### Explain code

```
POST http://localhost:8000/api/ai/explain
{
  "code": "def add(a,b): return a+b"
}
```

### Generate code

```
POST http://localhost:8000/api/ai/generate
{
  "instruction": "Write a function that checks if a number is prime."
}
```

---

# ğŸš€ Future Improvements (Planned)

- Streaming responses (like ChatGPT typing)
- Monaco editor (VS Code in browser)
- File uploads
- Multi-file analysis
- Dark mode
- Project-level code assistance
- Python execution sandbox

---

# ğŸ¤ Contributing

Pull requests welcome!
Always test backend + frontend together before submitting changes.

---

# ğŸ“ License

MIT License (Free to use, modify, distribute)

---

# ğŸ‰ Final Notes

This project is a **full standalone AI developer assistant**.
You can:

- Run it locally
- Deploy it on a server
- Improve the model through training
- Extend the UI
