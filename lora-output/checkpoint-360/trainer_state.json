{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 2.299560308456421,
      "learning_rate": 3.6e-05,
      "loss": 2.4567,
      "step": 10
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.7490757703781128,
      "learning_rate": 7.6e-05,
      "loss": 2.0634,
      "step": 20
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9545339345932007,
      "learning_rate": 0.000116,
      "loss": 2.0533,
      "step": 30
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 2.2765138149261475,
      "learning_rate": 0.00015600000000000002,
      "loss": 1.842,
      "step": 40
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 2.578070640563965,
      "learning_rate": 0.000196,
      "loss": 1.6199,
      "step": 50
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.217442035675049,
      "learning_rate": 0.00019419354838709678,
      "loss": 1.1702,
      "step": 60
    },
    {
      "epoch": 0.5833333333333334,
      "grad_norm": 2.468252182006836,
      "learning_rate": 0.00018774193548387098,
      "loss": 1.3507,
      "step": 70
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 3.6091294288635254,
      "learning_rate": 0.0001812903225806452,
      "loss": 1.0121,
      "step": 80
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.5528829097747803,
      "learning_rate": 0.00017483870967741936,
      "loss": 1.0075,
      "step": 90
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 4.055369853973389,
      "learning_rate": 0.00016838709677419354,
      "loss": 0.9303,
      "step": 100
    },
    {
      "epoch": 0.8333333333333334,
      "eval_loss": 0.8913698196411133,
      "eval_runtime": 65.4138,
      "eval_samples_per_second": 0.306,
      "eval_steps_per_second": 0.306,
      "step": 100
    },
    {
      "epoch": 0.9166666666666666,
      "grad_norm": 2.499469757080078,
      "learning_rate": 0.00016193548387096775,
      "loss": 1.0344,
      "step": 110
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.05281400680542,
      "learning_rate": 0.00015548387096774195,
      "loss": 0.9232,
      "step": 120
    },
    {
      "epoch": 1.0833333333333333,
      "grad_norm": 4.151229381561279,
      "learning_rate": 0.00014903225806451613,
      "loss": 0.8187,
      "step": 130
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 3.9382288455963135,
      "learning_rate": 0.00014258064516129034,
      "loss": 0.9018,
      "step": 140
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.82077693939209,
      "learning_rate": 0.00013612903225806452,
      "loss": 0.7308,
      "step": 150
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 3.4376487731933594,
      "learning_rate": 0.00012967741935483872,
      "loss": 0.8516,
      "step": 160
    },
    {
      "epoch": 1.4166666666666667,
      "grad_norm": 4.09093713760376,
      "learning_rate": 0.0001232258064516129,
      "loss": 0.7149,
      "step": 170
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.45042610168457,
      "learning_rate": 0.0001167741935483871,
      "loss": 1.0357,
      "step": 180
    },
    {
      "epoch": 1.5833333333333335,
      "grad_norm": 3.3093385696411133,
      "learning_rate": 0.0001103225806451613,
      "loss": 0.8673,
      "step": 190
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 2.705599308013916,
      "learning_rate": 0.0001038709677419355,
      "loss": 0.6719,
      "step": 200
    },
    {
      "epoch": 1.6666666666666665,
      "eval_loss": 0.6728693842887878,
      "eval_runtime": 65.8886,
      "eval_samples_per_second": 0.304,
      "eval_steps_per_second": 0.304,
      "step": 200
    },
    {
      "epoch": 1.75,
      "grad_norm": 4.743600368499756,
      "learning_rate": 9.741935483870968e-05,
      "loss": 0.7054,
      "step": 210
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 2.7608096599578857,
      "learning_rate": 9.096774193548387e-05,
      "loss": 0.8583,
      "step": 220
    },
    {
      "epoch": 1.9166666666666665,
      "grad_norm": 1.5984529256820679,
      "learning_rate": 8.451612903225808e-05,
      "loss": 0.7123,
      "step": 230
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.7530789375305176,
      "learning_rate": 7.806451612903226e-05,
      "loss": 0.6578,
      "step": 240
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 5.722115516662598,
      "learning_rate": 7.161290322580646e-05,
      "loss": 0.6768,
      "step": 250
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 6.230745792388916,
      "learning_rate": 6.516129032258065e-05,
      "loss": 0.7101,
      "step": 260
    },
    {
      "epoch": 2.25,
      "grad_norm": 7.206458568572998,
      "learning_rate": 5.870967741935483e-05,
      "loss": 0.7605,
      "step": 270
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 2.5138940811157227,
      "learning_rate": 5.225806451612903e-05,
      "loss": 0.6514,
      "step": 280
    },
    {
      "epoch": 2.4166666666666665,
      "grad_norm": 4.289438247680664,
      "learning_rate": 4.580645161290323e-05,
      "loss": 0.5752,
      "step": 290
    },
    {
      "epoch": 2.5,
      "grad_norm": 5.328176021575928,
      "learning_rate": 3.935483870967742e-05,
      "loss": 0.5869,
      "step": 300
    },
    {
      "epoch": 2.5,
      "eval_loss": 0.5976248979568481,
      "eval_runtime": 65.2973,
      "eval_samples_per_second": 0.306,
      "eval_steps_per_second": 0.306,
      "step": 300
    },
    {
      "epoch": 2.5833333333333335,
      "grad_norm": 7.428987503051758,
      "learning_rate": 3.2903225806451614e-05,
      "loss": 0.5185,
      "step": 310
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 3.0742568969726562,
      "learning_rate": 2.645161290322581e-05,
      "loss": 0.6122,
      "step": 320
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.657541513442993,
      "learning_rate": 2e-05,
      "loss": 0.6398,
      "step": 330
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 4.450843811035156,
      "learning_rate": 1.3548387096774195e-05,
      "loss": 0.6471,
      "step": 340
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 4.597248554229736,
      "learning_rate": 7.096774193548387e-06,
      "loss": 0.7531,
      "step": 350
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.856672763824463,
      "learning_rate": 6.451612903225807e-07,
      "loss": 0.7123,
      "step": 360
    }
  ],
  "logging_steps": 10,
  "max_steps": 360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 337238147727360.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
